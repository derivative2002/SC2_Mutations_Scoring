# 双打突变难度评估技术规划（仅考虑双指挥官场景）

以下方案针对当前数据集中“地图、指挥官组合、突变因子组合、AI”四个核心特征，以 1-5 分难度评分为目标进行模型构建与训练。重点聚焦双打模式，不考虑单指挥官（单刷）情形，从而简化部分特征与规则设计。此外，在部分关键指标和公式中引入 LaTeX 形式的数学表达，更清晰地说明模型的计算过程。

---

## 1. 需求与目标

1. **评分标准**  
   - 采用双打评分标准（1~5 分），如“简单 / 普通 / 困难 / 专家 / 残酷”五个等级；  
   - 已有标注基本完成，数据规模主要包含：  
     - 地图 (map)  
     - 指挥官组合 (commander1, commander2)  
     - 突变因子组合 (mutation factors)  
     - AI（敌方势力/类型等）  
     - 目标分数 (难度 1~5)

2. **主要输出**  
   - 输入上述关键特征后，获得一个预测分数 (1~5)，表示双打突变的整体难度；  
   - 后续可视需要映射成具体难度等级标签（如 1 = 简单, 5 = 残酷）。

---

## 2. 数据概述与预处理

1. **数据字段**  
   - 地图: map_id  
   - 指挥官组合: \(\text{commanderA}, \text{commanderB}\)  
   - 因子组合: \([\text{factor}_1, \text{factor}_2, \dots]\)  
   - AI: enemy_ai  
   - 难度标签: \(\text{difficulty} \in \{1,2,3,4,5\}\)

2. **数据预处理要点**  
   - **指挥官统一**：固定指挥官在 (commanderA, commanderB) 的字段顺序（如按 ID 大小排序），避免同一组合被视为两条不同数据；  
   - **突变因子拆分**：统一拆分与清洗，形成标准数组或 ID 索引；  
   - **稀疏特征合并**：对极少出现的地图 / 指挥官 / 因子可进行合并或剔除，减少无效数据。

---

## 3. 特征设计与模型结构

### 3.1 特征表示

1. **地图 Embedding**  
   - 令每张地图对应一个可学习向量 \(\mathbf{e}_{\text{map}} \in \mathbb{R}^d\)；  
   - map_id → \(\mathbf{e}_{\text{map}}\)。

2. **指挥官组合 Embedding**  
   - 指挥官 A： \(\mathbf{e}_{\text{cmdA}} \in \mathbb{R}^d\)，指挥官 B： \(\mathbf{e}_{\text{cmdB}} \in \mathbb{R}^d\)；  
   - 若做拼接：\(\mathbf{e}_{\text{cmdAB}} = [\mathbf{e}_{\text{cmdA}}, \mathbf{e}_{\text{cmdB}}]\in \mathbb{R}^{2d}\)；  
   - 或者简单加和：\(\mathbf{e}_{\text{cmdAB}} = \mathbf{e}_{\text{cmdA}} + \mathbf{e}_{\text{cmdB}} \in \mathbb{R}^{d}\)。

3. **突变因子组合 Embedding**  
   - 每个突变因子 \(\text{factor}_i\) 分配一个向量 \(\mathbf{e}_{\text{factor}_i} \in \mathbb{R}^d\)；  
   - 对全部突变因子做 Pooling，如平均 \(\displaystyle \mathbf{e}_{\text{factors}} = \frac{1}{k}\sum_{i=1}^{k}\mathbf{e}_{\text{factor}_i}\)。  
   - 若想捕捉强力交互，可考虑基于自注意力或轻量级的 GNN，但这里先用简单 Pooling。

4. **AI Embedding**  
   - enemy_ai → \(\mathbf{e}_{\text{AI}} \in \mathbb{R}^d\)，或 One-hot 若种类很有限。

5. **融合**  
   - 将上述向量拼接，得到  
     \[
       \mathbf{x} = 
       \begin{cases}
       [\,\mathbf{e}_{\text{map}},\;\mathbf{e}_{\text{cmdAB}},\;\mathbf{e}_{\text{factors}},\;\mathbf{e}_{\text{AI}}\,], & \text{若拼接维度相同;} \\
       (\mathbf{e}_{\text{map}} + \mathbf{e}_{\text{cmdAB}} + \mathbf{e}_{\text{factors}} + \mathbf{e}_{\text{AI}}), & \text{其他结构或加权融合.}
       \end{cases}
     \]

### 3.2 模型结构

假设采用简单 MLP：

1. **输入层**：\(\mathbf{x}\)（高维拼接向量）；  
2. **隐藏层**：  
   \[
   \mathbf{h}_1 = \sigma(\mathbf{W}_1\,\mathbf{x} + \mathbf{b}_1), \quad
   \mathbf{h}_2 = \sigma(\mathbf{W}_2\,\mathbf{h}_1 + \mathbf{b}_2),
   \]
   其中 \(\sigma(\cdot)\) 为非线性激活函数 (如 ReLU)。  
3. **输出层**：  
   - 若使用回归思路：输出 \(\hat{y} \in \mathbb{R}\)，然后约束或取整到 \(\{1,2,3,4,5\}\)。  
   - 若使用五分类思路：输出 \(\hat{\mathbf{p}} \in \mathbb{R}^5\) 后做 Softmax 归一化即可。

---

## 4. 训练流程与评估

### 4.1 训练流程

1. **数据划分**  
   - 训练集 / 验证集 (或 K-fold 交叉验证)，确保各个分数层均有分布；  
2. **初始化**  
   - 随机初始化 \(\mathbf{e}_{\text{map}}, \mathbf{e}_{\text{cmds}}, \mathbf{e}_{\text{factors}}, \mathbf{e}_{\text{AI}}\)；  
3. **前向传播**  
   - 对每条样本 \(\mathbf{x}_i\)，模型输出 \(\hat{y}_i\)。  
4. **损失函数**  
   - 回归场景：  
     \[
       \mathcal{L}_{\mathrm{MSE}} = \frac{1}{N}\sum_{i=1}^{N} (\hat{y}_i - y_i)^2,
     \]
     \[
       \mathcal{L}_{\mathrm{MAE}} = \frac{1}{N}\sum_{i=1}^{N} |\hat{y}_i - y_i|.
     \]
   - 分类场景（五分类）：  
     \[
       \mathcal{L}_{\mathrm{CE}} = -\frac{1}{N}\sum_{i=1}^{N} \sum_{c=1}^{5} \delta_{(y_i=c)} \cdot \log\bigl(\hat{p}_{i,c}\bigr),
     \]
     其中 \(\hat{p}_{i,c}\) 表示第 \(i\) 个样本在类别 \(c\) 上的预测概率，\(\delta_{(y_i=c)}\) 为指示函数。  
5. **反向传播与优化**  
   - 使用 SGD / Adam 等优化器迭代更新参数，直到验证集上收敛或触发 early stopping；  
6. **验证**  
   - 在验证集计算损失或准确率、MAE 等衡量，观察难度预测分布与真实分数分布的一致性。

### 4.2 评估指标

1. **回归指标**  
   - \(\mathrm{MAE}\) / \(\mathrm{RMSE}\)；若最终是五档离散值，也可查看 \(|\hat{y_i} - y_i|\le 1\) 的准确率等。  
2. **分类指标**  
   - 五分类准确率 / F1 分数；查看混淆矩阵判断在哪些难度段最易出错。  

---

## 5. 关键难点与应对

1. **数据量有限，特征稀疏**  
   - 减少 embedding 维度；  
   - 合并少见突变因子或地图，加大正则化力度。  
2. **交互作用缺失**  
   - 对确有强力因子叠加的情况，可设置二值 \(\mathrm{combo\_flag}\) 特征或稍后引入注意力/GNN；  
3. **指挥官组合的相对顺序**  
   - 固定 (commanderA, commanderB) 排列方式，避免数据重复。  
4. **容错与资源管理细节**  
   - 目前默认由数据中的\(\text{difficulty}\)标签学习到隐式特征；若后续数据充分，可显式增加此类特征（如“经济压力”评分）。

---

## 6. 后续扩展与改进

1. **加入单指挥官场景**  
   - 在输入中增设模式 \(\mathrm{isDuo}\in\{0,1\}\) 的 embedding；输出后再根据不同评分标准映射到最终难度；  
   - 或者建独立的“单刷”模型并与本模型并行。  
2. **对比标注 (Pairwise)**  
   - 可与绝对打分混合，用多任务学习的思路：  
     \[
       \mathcal{L} = \alpha \cdot \mathcal{L}_{\mathrm{reg}} + (1-\alpha) \cdot \mathcal{L}_{\mathrm{rank}},
     \]
     改善标注噪声与小数据过拟合问题。  
3. **更复杂网络结构**  
   - 当数据量增加后，可使用 Transformer / Graph Neural Network 来显式建模指挥官、因子、AI 等节点的交互；  
   - 也可考虑多头自注意力以捕捉突变因子之间的协同放大效应。  
4. **规则融合**  
   - 基于专家经验，对部分极端组合进行输出强制修正（如自动加 0.5~1 分），提高模型在小样本下的稳定性。

---

## 7. 小结

在仅考虑双打模式、使用 1~5 分进行难度标注的场景中，可采取轻量级的 Embedding + MLP 方案，对“地图、指挥官组合、突变因子、AI”进行分层向量化后融合，输出一个五档难度预测结果。通过在损失函数中使用 \(\mathrm{MAE}\) / \(\mathrm{MSE}\)（回归）或交叉熵（五分类）进行训练，并结合适度的先验规则或稀疏处理，可在小规模数据下实现初步且实用的双打突变难度估计模型。后续若不断补充数据（包括对比标注、Replay 信息等）并引入更复杂的网络结构，即可进一步提升对多重突变因子协同作用的识别精度与解释性。
